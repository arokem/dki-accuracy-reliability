{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "if 'sc' not in locals():\n",
    "    sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is already in place. If you want to fetch it again please first remove the folder /root/AFQ_data/templates \n"
     ]
    }
   ],
   "source": [
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subjects = [int(s) for s in np.loadtxt('./hcp900.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_nodes = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_subjects = len(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_lists = []\n",
    "for i in range(round(n_subjects/n_nodes)):\n",
    "    sub_lists.append(subjects[n_nodes*i:n_nodes*(i+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100206, True), (100307, True), (100408, True), (100610, True), (101006, True), (101107, True), (101309, True), (101410, True), (101915, True), (102311, True), (102513, True), (102816, True), (103111, True), (103414, True), (103515, True), (103818, True), (104012, True), (104416, True), (104820, True), (105014, True), (105115, True), (105216, True), (105620, True), (105923, True), (106016, True)]\n",
      "[(106319, True), (106521, True), (107018, True), (107321, True), (107422, True), (107725, True), (108121, True), (108222, True), (108323, True), (108525, True), (108828, True), (109123, True), (109325, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (109830, True), (110007, True), (110411, True), (110613, True), (111009, True), (111312, True), (111413, True), (111514, True), (111716, True), (112112, True), (112314, True), (112516, True)]\n",
      "[(112819, True), (112920, True), (113215, True), (113619, True), (113821, True), (113922, True), (114217, True), (114318, ('np.mod(179, 5) is 4',)), (114419, True), (114621, True), (114823, True), (114924, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (115017, True), (115219, ('np.mod(179, 5) is 4',)), (115320, True), (115825, True), (116120, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (116221, True), (116524, True), (116726, True), (117122, True), (117324, True), (117930, True), (118023, ('np.mod(179, 5) is 4',)), (118124, True)]\n",
      "[(118225, True), (118528, True), (118730, True), (118932, True), (119126, True), (119732, True), (119833, True), (120111, True), (120212, True), (120515, True), (120717, True), (121315, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (121416, True), (121618, True), (121820, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (121921, True), (122317, True), (122620, True), (122822, True), (123117, True), (123420, True), (123521, True), (123824, ('np.mod(179, 5) is 4',)), (123925, True), (124220, True)]\n",
      "[(124422, True), (124624, True), (124826, True), (125525, True), (126325, True), (126628, True), (126931, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (127327, ('np.mod(179, 5) is 4',)), (127630, True), (127933, True), (128026, True), (128127, True), (128329, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (128632, True), (128935, True), (129028, True), (129129, True), (129331, True), (129432, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (129533, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (129634, True), (129937, True), (130013, True), (130316, True), (130417, True)]\n",
      "[(130619, True), (130821, True), (130922, True), (131217, True), (131419, True), (131621, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (131722, True), (131823, True), (131924, True), (132017, True), (132118, ('np.mod(179, 5) is 4',)), (133019, True), (133625, True), (133827, True), (133928, True), (134021, True), (134223, True), (134324, ('np.mod(179, 5) is 4',)), (134425, True), (134728, True), (134829, True), (135225, True), (135528, True), (135730, True), (135932, True)]\n",
      "[(136227, True), (136732, True), (136833, True), (137027, ('np.mod(179, 5) is 4',)), (137128, ('np.mod(181, 5) is 1',)), (137229, True), (137633, True), (137936, ('np.mod(179, 5) is 4',)), (138231, True), (138534, True), (138837, True), (139233, True), (139637, True), (139839, True), (140117, True), (140319, True), (140420, True), (140824, True), (140925, True), (141119, True), (141422, True), (141826, True), (142424, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (142828, ('np.mod(179, 5) is 4',)), (143325, True)]\n",
      "[(143426, ('np.mod(179, 5) is 4',)), (143527, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (144125, True), (144226, True), (144428, True), (144731, True), (144832, True), (145127, True), (145531, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (145834, True), (146129, True), (146331, True), (146432, True), (146533, True), (146634, True), (146937, True), (147030, True), (147737, True), (148032, True), (148133, True), (148335, True), (148436, ('np.mod(179, 5) is 4',)), (148840, True), (148941, True), (149236, True)]\n",
      "[(149337, True), (149539, True), (149741, True), (149842, True), (150019, True), (150423, ('np.mod(89, 5) is 4',)), (150524, ('np.mod(179, 5) is 4',)), (150625, True), (150726, True), (150928, True), (151223, True), (151425, True), (151526, True), (151627, True), (151728, True), (151829, True), (152831, True), (153025, True), (153227, True), (153429, True), (153631, ('np.mod(269, 5) is 4',)), (153732, True), (153833, ('np.mod(179, 5) is 4',)), (154229, True), (154431, True)]\n",
      "[(154532, True), (154734, True), (154835, True), (154936, True), (155231, True), (155635, True), (155938, True), (156031, True), (156233, True), (156334, True), (156435, True), (156536, True), (156637, True), (157336, True), (157437, True), (157942, True), (158035, True), (158136, True), (158338, True), (158540, True), (158843, True), (159138, True), (159239, True), (159340, True), (159441, True)]\n",
      "[(159744, True), (159845, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (159946, True), (160123, True), (160729, ('np.mod(179, 5) is 4',)), (160830, True), (160931, True), (161327, True), (161630, True), (161731, True), (162026, True), (162228, True), (162329, True), (162733, True), (162935, True), (163129, True), (163331, True), (163432, ('np.mod(179, 5) is 4',)), (163836, True), (164030, True), (164131, True), (164636, True), (164939, True), (165032, True), (165234, ('An error occurred (404) when calling the HeadObject operation: Not Found',))]\n",
      "[(165638, True), (165840, True), (166438, True), (166640, ('np.mod(179, 5) is 4',)), (167036, True), (167238, True), (167743, ('np.mod(179, 5) is 4',)), (168038, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (168139, True), (168240, True), (168341, True), (168745, True), (169040, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (169141, ('An error occurred (404) when calling the HeadObject operation: Not Found',)), (169343, True), (169444, True), (169747, True), (169949, True), (170631, True), (170934, True), (171330, True), (171431, ('np.mod(179, 5) is 4',)), (171532, True), (171633, True), (172029, True)]\n",
      "[(172130, True), (172332, True), (172433, True), (172534, True), (172938, True), (173132, ('np.mod(179, 5) is 4',)), (173233, ('np.mod(179, 5) is 4',)), (173334, True), (173435, True), (173536, True), (173637, True), (173738, True), (173839, True), (173940, True), (174437, True), (174841, True), (175035, True), (175237, True), (175338, True), (175439, True), (175540, True), (175742, True), (176037, True), (176239, True), (176441, True)]\n",
      "[(176542, True), (176744, True), (177241, True), (177342, ('np.mod(179, 5) is 4',)), (177645, True), (177746, True), (178142, True), (178243, True), (178647, True), (178748, ('np.mod(179, 5) is 4',)), (178849, True), (178950, True), (179245, True), (179346, True), (179548, True), (179952, True), (180129, True), (180432, True), (180735, True), (180836, True), (180937, True), (181131, True), (181232, True), (181636, True), (182032, True)]\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 239 in stage 14.0 failed 4 times, most recent failure: Lost task 239.3 in stage 14.0 (TID 4089, ip-172-31-36-192.ec2.internal): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: worker lost\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:926)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:405)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-db0f37a57849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msubRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel_compareRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mthis_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_compareRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_compare_lists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \"\"\"\n\u001b[1;32m    770\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[0;32m--> 813\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/spark/python/lib/py4j-0.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    306\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    307\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 239 in stage 14.0 failed 4 times, most recent failure: Lost task 239.3 in stage 14.0 (TID 4089, ip-172-31-36-192.ec2.internal): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: worker lost\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:927)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:316)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:926)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:405)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "model_compare_lists = []\n",
    "for this_list in sub_lists:\n",
    "    subRDD = sc.parallelize(this_list)\n",
    "    model_compareRDD = subRDD.map(tools.compare_models)\n",
    "    this_list = model_compareRDD.collect()\n",
    "    print(this_list)\n",
    "    model_compare_lists.append(this_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_compare_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
